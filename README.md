# awesome-DocumentAI



<!-- 

1. **[[]]()** x. x. [[code](x)] 

    *x* 

-->

### MM 2022

1. **[[LayoutLMv3'22]](https://arxiv.org/pdf/2204.08387)** LayoutLMv3: Pre-training for Document AI with Unified Text and Image Masking. MM 2022. [[code](x)] 

    *Y Huang, T Lv, L Cui, Y Lu, F Wei.* 
2. **[[DiT'22]](https://arxiv.org/pdf/2203.02378v3.pdf)** DiT: Self-supervised Pre-training for Document Image Transformer. MM 2022. [[code](https://github.com/microsoft/unilm/tree/master/dit)]

    *Junlong Li, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei.* 
    
### CVPR 2022

1. **[[XYLayoutLM'22]](https://arxiv.org/abs/2203.06947)** XYLayoutLM: Towards Layout-Aware Multimodal Networks For Visually-Rich Document Understanding. CVPR 2022. 

    *Zhangxuan Gu, Changhua Meng, Ke Wang, Jun Lan, Weiqiang Wang, Ming Gu, Liqing Zhang.* 

### ECCV 2022 

### Others 2022

1. **[[DocTTA'22]](https://arxiv.org/pdf/2206.07240.pdf)** Test-Time Adaptation for Visual Document Understanding. 2022.  

    *Sayna Ebrahimi, Sercan Ö. Arık, Tomas Pfister.* 

1. **[[X'22]](https://arxiv.org/pdf/2208.08201.pdf)** Understanding Long Documents with Different Position-Aware Attentions. 2022. 

    *Hai Pham†∗ , Guoxin Wang‡ , Yijuan Lu‡ , Dinei Florencio‡ , Cha Zhang‡.* 
